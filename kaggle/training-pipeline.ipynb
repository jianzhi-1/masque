{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9877454,"sourceType":"datasetVersion","datasetId":6064207},{"sourceId":9878494,"sourceType":"datasetVersion","datasetId":6064962},{"sourceId":161068,"sourceType":"modelInstanceVersion","modelInstanceId":136968,"modelId":159690},{"sourceId":163874,"sourceType":"modelInstanceVersion","modelInstanceId":139391,"modelId":162020}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Init\nInstall and import libraries, set up logging.","metadata":{}},{"cell_type":"code","source":"!pip install librosa\n!pip install soundfile\n!pip install speechbrain","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-12-08T19:11:39.307442Z","iopub.execute_input":"2024-12-08T19:11:39.307796Z","iopub.status.idle":"2024-12-08T19:12:05.641039Z","shell.execute_reply.started":"2024-12-08T19:11:39.307761Z","shell.execute_reply":"2024-12-08T19:12:05.639900Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport librosa\nimport matplotlib.pyplot as plt\nimport soundfile as sf\n\nimport logging\n\nfrom speechbrain.inference.vocoders import HIFIGAN\nfrom speechbrain.inference.TTS import Tacotron2\nfrom speechbrain.lobes.models.FastSpeech2 import mel_spectogram\n\nimport IPython.display as ipd\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn.utils.rnn import pad_sequence\nimport torchaudio\n\nfrom datasets import load_dataset # Expresso dataset\nimport tqdm.notebook","metadata":{"execution":{"iopub.status.busy":"2024-12-08T19:12:05.643405Z","iopub.execute_input":"2024-12-08T19:12:05.643804Z","iopub.status.idle":"2024-12-08T19:12:10.774606Z","shell.execute_reply.started":"2024-12-08T19:12:05.643759Z","shell.execute_reply":"2024-12-08T19:12:10.773919Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for handler in logging.root.handlers[:]:\n    logging.root.removeHandler(handler)\n\nlogging.basicConfig(filename='transformer.log', \n                    level=logging.DEBUG,\n                    format='%(asctime)s - %(levelname)s - %(message)s')\n\nassert torch.cuda.is_available()\ndevice = torch.device(\"cuda\")\nprint(\"Using device:\", device)","metadata":{"execution":{"iopub.status.busy":"2024-12-08T19:12:10.775635Z","iopub.execute_input":"2024-12-08T19:12:10.776165Z","iopub.status.idle":"2024-12-08T19:12:10.783374Z","shell.execute_reply.started":"2024-12-08T19:12:10.776125Z","shell.execute_reply":"2024-12-08T19:12:10.782449Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Utils\nDefine utility functions and load processed dataset.","metadata":{}},{"cell_type":"code","source":"EPS = 1e-6\n\ndef equals(a, b):\n    return abs(a - b) < EPS\n\ndef dtw(a, b):\n    n, m = a.shape[0], b.shape[0]\n    dtw_matrix = np.full((n + 1, m + 1), np.inf)\n    dtw_matrix[0, 0] = 0\n\n    for i in range(1, n + 1):\n        for j in range(1, m + 1):\n            cost = np.linalg.norm(a[i - 1] - b[j - 1])  # Euclidean distance\n            dtw_matrix[i, j] = cost + min(dtw_matrix[i - 1, j],    # Insertion\n                                           dtw_matrix[i, j - 1],    # Deletion\n                                           dtw_matrix[i - 1, j - 1]) # Match\n\n    # Backtrack to find the optimal path\n    i, j = n, m\n    path = []\n\n    while i > 0 or j > 0:\n        path.append((i - 1, j - 1))\n        if i > 0 and j > 0:\n            if equals(dtw_matrix[i, j], dtw_matrix[i - 1, j - 1] + np.linalg.norm(a[i - 1] - b[j - 1])):\n                i -= 1\n                j -= 1\n            elif equals(dtw_matrix[i, j], dtw_matrix[i - 1, j] + np.linalg.norm(a[i - 1] - b[j - 1])):\n                i -= 1\n            else:\n                j -= 1\n        elif i > 0:\n            i -= 1\n        else:\n            j -= 1\n\n    path.reverse()\n    return dtw_matrix[n, m], path\n\ndef load_audio(file_path):\n    y, sr = librosa.load(file_path, sr=None)\n    return y, sr\n\ndef align(signal_a, signal_b, path):\n    aligned_b = np.zeros_like(signal_a)\n\n    for idx_a, idx_b in path:\n        aligned_b[idx_a] = signal_b[idx_b]\n\n    return aligned_b\n\ndef main(audio_file_1, audio_file_2):\n    \n    # 0. Load audio files\n    audio_a, sr_a = load_audio(audio_file_1)\n    audio_b, sr_b = load_audio(audio_file_2)\n\n    # 1. Extract MFCC features\n    mfcc_a = librosa.feature.mfcc(y=audio_a, sr=sr_a, n_mfcc=13).T\n    mfcc_b = librosa.feature.mfcc(y=audio_b, sr=sr_b, n_mfcc=13).T\n\n    # 2. Normalise MFCC features\n    mfcc_a_normalised = (mfcc_a - np.mean(mfcc_a, axis=0))/(np.std(mfcc_a, axis=0))\n    mfcc_b_normalised = (mfcc_b - np.mean(mfcc_b, axis=0))/(np.std(mfcc_b, axis=0))\n\n    # 3. Perform DTW\n    _, path = dtw(mfcc_a_normalised, mfcc_b_normalised)\n\n    # 4. Align audio_b using DTW path\n    mfcc_b_aligned = align_mfcc(mfcc_a_normalised, mfcc_b, path)\n    audio_b_aligned = librosa.feature.inverse.mfcc_to_audio(np.einsum(\"ij->ji\", mfcc_b_aligned))\n\n    # 5. Export\n    sf.write(f'./{audio_file_2}_aligned.wav', audio_b_aligned, sr_b)\n    print(f\"Aligned audio saved as '{audio_file_2}_aligned.wav'.\")\n\n    return\n\ndef naive_cut(audio_file_1, audio_file_2):\n    audio_a, _ = load_audio(audio_file_1)\n    audio_b, sr_b = load_audio(audio_file_2)\n    sf.write('./audio_b_cut.wav', audio_b[:len(audio_a)], sr_b)\n    print(\"Aligned audio saved as 'audio_b_cut.wav'.\")\n\ndef naive_speed(audio_file_1, audio_file_2):\n    audio_a, sr_a = load_audio(audio_file_1)\n    audio_b, _ = load_audio(audio_file_2)\n    sf.write('./audio_b_speed.wav', audio_b, int(sr_a*len(audio_b)/len(audio_a)))\n    print(\"Aligned audio saved as 'audio_b_speed.wav'.\")","metadata":{"execution":{"iopub.status.busy":"2024-12-08T19:12:10.785142Z","iopub.execute_input":"2024-12-08T19:12:10.785394Z","iopub.status.idle":"2024-12-08T19:12:10.798898Z","shell.execute_reply.started":"2024-12-08T19:12:10.785369Z","shell.execute_reply":"2024-12-08T19:12:10.798022Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load a pretrained HIFIGAN Vocoder\ntacotron2 = Tacotron2.from_hparams(source=\"speechbrain/tts-tacotron2-ljspeech\", savedir=\"tmpdir_tts\")\nhifi_gan = HIFIGAN.from_hparams(source=\"speechbrain/tts-hifigan-ljspeech\", savedir=\"tmpdir_vocoder\")\n\ndef view_spectrogram(spectrogram, title=\"Mel Spectrogram\", n_mels=80):\n    if not isinstance(spectrogram, np.ndarray):\n        spectrogram = spectrogram.numpy()\n    if spectrogram.shape[0] != 80:\n        spectrogram = np.einsum(\"ij->ji\", spectrogram)\n    assert spectrogram.shape[0] == n_mels, f\"spectrogram shape {spectrogram.shape} != ({n_mels}, seq_length)\"\n    print(spectrogram.shape)\n    plt.figure(figsize=(10, 4))\n    librosa.display.specshow(spectrogram, sr=22050, x_axis='time', y_axis='mel', fmax=8000)\n    plt.colorbar(format='%+2.0f dB')\n    plt.title(title)\n    plt.tight_layout()\n    plt.show()\n\ndef get_spectrogram(file_name):\n\n    signal, rate = torchaudio.load(file_name)\n    signal = torchaudio.functional.resample(signal, orig_freq=rate, new_freq=22050)\n\n    spectrogram, _ = mel_spectogram(\n        audio=signal.squeeze(),\n        sample_rate=22050,\n        hop_length=256,\n        win_length=None,\n        n_mels=80,\n        n_fft=1024,\n        f_min=0.0,\n        f_max=8000.0,\n        power=1,\n        normalized=False,\n        min_max_energy_norm=True,\n        norm=\"slaney\",\n        mel_scale=\"slaney\",\n        compression=True\n    )\n\n    return spectrogram\n\ndef get_spectrogram_from_waveform(signal, rate):\n    \n    if isinstance(signal, np.ndarray):\n        signal = torch.tensor(signal, dtype=torch.float32)\n    \n    signal = torchaudio.functional.resample(signal, orig_freq=rate, new_freq=22050)\n\n    spectrogram, _ = mel_spectogram(\n        audio=signal.squeeze(),\n        sample_rate=22050,\n        hop_length=256,\n        win_length=None,\n        n_mels=80,\n        n_fft=1024,\n        f_min=0.0,\n        f_max=8000.0,\n        power=1,\n        normalized=False,\n        min_max_energy_norm=True,\n        norm=\"slaney\",\n        mel_scale=\"slaney\",\n        compression=True\n    )\n\n    return spectrogram\n\ndef spectrogram_to_waveform(spectrogram, save_file_name):\n    waveforms = hifi_gan.decode_batch(spectrogram) # spectrogram to waveform\n    torchaudio.save(save_file_name, waveforms.squeeze(1), 22050)\n\ndef get_reconstructed_sample(file_name, save_file_name):\n\n    signal, rate = torchaudio.load(file_name)\n    signal = torchaudio.functional.resample(signal, orig_freq=rate, new_freq=22050)\n\n    spectrogram, _ = mel_spectogram(\n        audio=signal.squeeze(),\n        sample_rate=22050,\n        hop_length=256,\n        win_length=None,\n        n_mels=80,\n        n_fft=1024,\n        f_min=0.0,\n        f_max=8000.0,\n        power=1,\n        normalized=False,\n        min_max_energy_norm=True,\n        norm=\"slaney\",\n        mel_scale=\"slaney\",\n        compression=True\n    )\n\n    waveforms = hifi_gan.decode_batch(spectrogram) # spectrogram to waveform\n\n    torchaudio.save(save_file_name, waveforms.squeeze(1), 22050)\n\ndef transcript_to_audio(sentence, save_file_name):\n    \n    mel_output, mel_length, alignment = tacotron2.encode_text(sentence)\n    # 1. Mel spectrogram with properties in the Tacotron paper (or see get_reconstructed_sample)\n    #    Shape = (batch_size, n_mels=80, Mel_length + 1); Mel_length proportional to length of sequence\n    # 2. Mel_length = mel_output.shape[2] - 1\n    # 3. Alignment\n    #    Shape = (batch_size, Mel_length, Token_length) where Token_length is from tacotron2.text_to_seq(txt)\n\n    waveforms = hifi_gan.decode_batch(mel_output) # spectrogram to waveform\n\n    torchaudio.save(save_file_name, waveforms.squeeze(1), 22050)\n\ndef transcript_to_mel(sentence):\n    mel_output, mel_length, alignment = tacotron2.encode_text(sentence)\n    return mel_output.squeeze() # remove the batch dimension\n\ndef mel_to_audio(mel_output, save_file_name=None, display=False):\n    if isinstance(mel_output, np.ndarray):\n        mel_output = torch.tensor(mel_output)\n    if mel_output.shape[0] != 80:\n        mel_output = torch.einsum(\"ij->ji\", mel_output)\n    waveforms = hifi_gan.decode_batch(mel_output) # spectrogram to waveform\n    if save_file_name is not None: torchaudio.save(save_file_name, waveforms.squeeze(1), 22050)\n    if display: return ipd.Audio(waveforms, rate=22050)\n    return waveforms\n\ndef sample_audio(dataset, idx:int):\n    print(dataset[idx])\n    mel_to_audio(torch.einsum(\"ij->ji\", dataset[idx][\"data_mel\"]), f\"sample_{idx}.wav\")\n    mel_to_audio(torch.einsum(\"ij->ji\", torch.tensor(dataset[idx][\"original_data_mel\"])), f\"sample_{idx}_original.wav\")","metadata":{"execution":{"iopub.status.busy":"2024-12-08T19:12:10.800144Z","iopub.execute_input":"2024-12-08T19:12:10.800716Z","iopub.status.idle":"2024-12-08T19:12:13.014834Z","shell.execute_reply.started":"2024-12-08T19:12:10.800689Z","shell.execute_reply":"2024-12-08T19:12:13.013832Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = torch.load(\"/kaggle/input/speaker4/speaker4.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-12-08T19:12:13.016105Z","iopub.execute_input":"2024-12-08T19:12:13.016453Z","iopub.status.idle":"2024-12-08T19:13:09.997940Z","shell.execute_reply.started":"2024-12-08T19:12:13.016416Z","shell.execute_reply":"2024-12-08T19:13:09.997232Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualise\nVisualise Mel spectrograms, audios, and standardise Mel spectrograms per channel.","metadata":{}},{"cell_type":"code","source":"dataset.keys()","metadata":{"execution":{"iopub.status.busy":"2024-12-08T19:15:01.156363Z","iopub.execute_input":"2024-12-08T19:15:01.156759Z","iopub.status.idle":"2024-12-08T19:15:01.162891Z","shell.execute_reply.started":"2024-12-08T19:15:01.156726Z","shell.execute_reply":"2024-12-08T19:15:01.162006Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset[\"training_data\"][0]","metadata":{"execution":{"iopub.status.busy":"2024-12-08T18:46:32.688143Z","iopub.execute_input":"2024-12-08T18:46:32.688971Z","iopub.status.idle":"2024-12-08T18:46:32.736039Z","shell.execute_reply.started":"2024-12-08T18:46:32.688938Z","shell.execute_reply":"2024-12-08T18:46:32.735160Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mu = torch.zeros(80)\nx_square = torch.zeros(80)\nsig = torch.zeros(80)\ntot = 0\n\nfor item in dataset[\"training_data\"]:\n    tot += item[\"ai_mel\"].size(0)\n    curmu = item[\"ai_mel\"].sum(axis=0)\n    mu = mu + curmu\n    x_square = x_square + (item[\"ai_mel\"]**2).sum(axis=0)\n\nmu /= tot\nsig = torch.sqrt(x_square/tot - mu*mu)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T19:55:48.723607Z","iopub.execute_input":"2024-12-08T19:55:48.724437Z","iopub.status.idle":"2024-12-08T19:55:48.809861Z","shell.execute_reply.started":"2024-12-08T19:55:48.724400Z","shell.execute_reply":"2024-12-08T19:55:48.808907Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mu_cuda = mu.to(device)\nsig_cuda = sig.to(device)\nmu_cuda, sig_cuda","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T19:55:56.865474Z","iopub.execute_input":"2024-12-08T19:55:56.865828Z","iopub.status.idle":"2024-12-08T19:55:56.878246Z","shell.execute_reply.started":"2024-12-08T19:55:56.865794Z","shell.execute_reply":"2024-12-08T19:55:56.877281Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mu_data = torch.zeros(80)\nx_square_data = torch.zeros(80)\nsig_data = torch.zeros(80)\ntot_data = 0\n\nfor item in dataset[\"training_data\"]:\n    tot_data += item[\"data_mel\"].size(0)\n    curmu_data = item[\"data_mel\"].sum(axis=0)\n    mu_data = mu_data + curmu_data\n    x_square_data = x_square_data + (item[\"data_mel\"]**2).sum(axis=0)\n\nmu_data /= tot_data\nsig_data = torch.sqrt(x_square_data/tot_data - mu_data*mu_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T19:55:59.746242Z","iopub.execute_input":"2024-12-08T19:55:59.746588Z","iopub.status.idle":"2024-12-08T19:55:59.840675Z","shell.execute_reply.started":"2024-12-08T19:55:59.746558Z","shell.execute_reply":"2024-12-08T19:55:59.839878Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mu_data_cuda = mu_data.to(device)\nsig_data_cuda = sig_data.to(device)\nmu_data_cuda, sig_data_cuda","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T19:56:05.872185Z","iopub.execute_input":"2024-12-08T19:56:05.872536Z","iopub.status.idle":"2024-12-08T19:56:05.884723Z","shell.execute_reply.started":"2024-12-08T19:56:05.872496Z","shell.execute_reply":"2024-12-08T19:56:05.883777Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"view_spectrogram(dataset[\"training_data\"][0][\"ai_mel\"], title=\"Mel Spectrogram\")","metadata":{"execution":{"iopub.status.busy":"2024-12-08T18:46:37.537482Z","iopub.execute_input":"2024-12-08T18:46:37.537838Z","iopub.status.idle":"2024-12-08T18:46:38.726392Z","shell.execute_reply.started":"2024-12-08T18:46:37.537809Z","shell.execute_reply":"2024-12-08T18:46:38.725567Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"view_spectrogram(dataset[\"training_data\"][0][\"data_mel\"], title=\"Mel Spectrogram\")","metadata":{"execution":{"iopub.status.busy":"2024-11-21T00:41:32.938177Z","iopub.execute_input":"2024-11-21T00:41:32.938417Z","iopub.status.idle":"2024-11-21T00:41:33.310519Z","shell.execute_reply.started":"2024-11-21T00:41:32.938394Z","shell.execute_reply":"2024-11-21T00:41:33.309683Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mel_to_audio(dataset[\"training_data\"][1][\"ai_mel\"], display=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-21T00:41:33.311638Z","iopub.execute_input":"2024-11-21T00:41:33.311912Z","iopub.status.idle":"2024-11-21T00:41:34.975524Z","shell.execute_reply.started":"2024-11-21T00:41:33.311885Z","shell.execute_reply":"2024-11-21T00:41:34.974628Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mel_to_audio(dataset[\"training_data\"][1][\"data_mel\"], display=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-21T00:41:34.976843Z","iopub.execute_input":"2024-11-21T00:41:34.977465Z","iopub.status.idle":"2024-11-21T00:41:35.41782Z","shell.execute_reply.started":"2024-11-21T00:41:34.977419Z","shell.execute_reply":"2024-11-21T00:41:35.416713Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ProcessedMelSpectrogramDataset(torch.utils.data.Dataset):\n    def __init__(self, split, data):\n        assert split in (\"train\", \"valid\", \"test\"), \"invalid split\"\n        m = {\n            \"train\": \"training_data\",\n            \"valid\": \"validation_data\",\n            \"test\": \"testing_data\"\n        }\n        self.data = data\n        self.split = m[split]\n        \n        import random\n        random.seed(225) # reproducibility\n        random.shuffle(self.data[\"training_data\"])\n\n    def __len__(self):\n        return len(self.data[self.split])\n\n    def __getitem__(self, idx:int):\n        assert idx >= 0 and idx < len(self), \"Index error in ProcessedMelSpectrogramDataset\"\n        return self.data[self.split][idx]\n    \n    @staticmethod\n    def collate(batch):\n        \n        assert torch.cuda.is_available()\n        device = torch.device(\"cuda\")\n        \n        ai_mel = pad_sequence(\n            [item[\"ai_mel\"] for item in batch],\n            batch_first=True, padding_value=np.nan\n        )\n        data_mel = pad_sequence(\n            [item[\"data_mel\"] for item in batch],\n            batch_first=True, padding_value=np.nan\n        )\n#         duration = pad_sequence(\n#             [item[\"duration\"] for item in batch],\n#             batch_first=True, padding_value=np.nan\n#         )\n        labels = torch.cat(tuple([item[\"label\"] for item in batch]))\n#         sequence_lengths = torch.cat(tuple([item[\"sequence_length\"] for item in batch]))\n        mask = torch.all(torch.where(torch.isnan(ai_mel), torch.full(ai_mel.shape, True), torch.full(ai_mel.shape, False)), 2)\n        mask_check = torch.all(torch.where(torch.isnan(data_mel), torch.full(data_mel.shape, True), torch.full(data_mel.shape, False)), 2)\n#         mask_double_check = torch.where(torch.isnan(duration), torch.full(duration.shape, True), torch.full(duration.shape, False))\n        assert torch.equal(mask, mask_check), \"mask is dubious\"\n#         assert torch.equal(mask, mask_double_check), f\"mask is dubious {mask.shape}, {mask_double_check.shape}\"\n\n        ai_mel = pad_sequence(\n            [(item[\"ai_mel\"] - mu)/sig for item in batch],\n            batch_first=True, padding_value=0.0\n        )\n        data_mel = pad_sequence(\n            [(item[\"data_mel\"] - mu_data)/sig_data for item in batch],\n            batch_first=True, padding_value=0.0\n        )\n#         duration = pad_sequence(\n#             [item[\"duration\"] for item in batch],\n#             batch_first=True, padding_value=0.0\n#         )\n        \n        batch_size = len(batch)\n        _, ai_mel_max_length, _ = ai_mel.shape\n        assert ai_mel.shape == (batch_size, ai_mel_max_length, 80)\n        assert data_mel.shape == ai_mel.shape\n#         assert duration.shape == ai_mel.shape[:2]\n#         assert sequence_lengths.shape == torch.Size([batch_size])\n#         assert torch.all(sequence_lengths > 0), \"not all sequence lengths are positive\"\n        assert mask.shape == ai_mel.shape[:2]\n        \n        return {\n            \"ai_mel\": ai_mel.to(device),\n            \"data_mel\": data_mel.to(device), \n            \"labels\": labels.to(device),\n#             \"sequence_length\": sequence_lengths.to(device),\n            \"mask\": mask.to(device) #,\n#             \"duration\": duration.to(device)\n        }","metadata":{"execution":{"iopub.status.busy":"2024-12-08T19:15:15.129266Z","iopub.execute_input":"2024-12-08T19:15:15.129973Z","iopub.status.idle":"2024-12-08T19:15:15.140528Z","shell.execute_reply.started":"2024-12-08T19:15:15.129923Z","shell.execute_reply":"2024-12-08T19:15:15.139699Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model\nDefine and initialise transformer model.","metadata":{}},{"cell_type":"code","source":"class EmotionModel(nn.Module):\n    def transform(self, batch):\n        raise NotImplementedError()\n\n    def compute_loss(self, batch):\n        batch_size, seq_length, mels_dim = batch[\"ai_mel\"].shape\n        assert batch[\"data_mel\"].shape == (batch_size, seq_length, mels_dim)\n\n        predicted_mel = self.transform(batch)\n        assert predicted_mel.shape == (batch_size, seq_length, mels_dim)\n\n        target_mel = batch[\"data_mel\"]\n        assert target_mel.shape == (batch_size, seq_length, mels_dim)\n\n        assert mels_dim == 80\n        loss = torch.sum((predicted_mel - target_mel)**2)\n        return loss\n  \n    def get_validation_metric(self, validation_dataset, batch_size=64):\n        dataset = validation_dataset # replace because of caching efficiency\n        data_loader = torch.utils.data.DataLoader(\n            dataset, batch_size=batch_size, collate_fn=dataset.collate\n        )\n        self.eval()\n        total_mse = 0.0\n        total = 0\n        with torch.no_grad():\n            for i, batch in enumerate(data_loader):\n                loss = self.compute_loss(batch)\n                total_mse += loss\n                total += batch[\"ai_mel\"].size(0)\n\n        return total_mse/total","metadata":{"execution":{"iopub.status.busy":"2024-12-08T19:15:16.840949Z","iopub.execute_input":"2024-12-08T19:15:16.841906Z","iopub.status.idle":"2024-12-08T19:15:16.852107Z","shell.execute_reply.started":"2024-12-08T19:15:16.841852Z","shell.execute_reply":"2024-12-08T19:15:16.851173Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class AddPositionalEncoding(nn.Module):\n    def __init__(self, d_model=256, input_dropout=0.1, timing_dropout=0.1, max_len=2048):\n        super().__init__()\n        self.max_len = max_len\n        self.timing_table = nn.Parameter(torch.zeros(max_len))\n        nn.init.normal_(self.timing_table)\n        self.input_dropout = nn.Dropout(input_dropout)\n        self.timing_dropout = nn.Dropout(timing_dropout)\n\n    def forward(self, x, mask):\n        batch_size, seq_length, d_model = x.shape\n        assert x.shape == (batch_size, seq_length, d_model)\n        assert mask.shape == (batch_size, seq_length)\n        assert seq_length < self.max_len\n        x = self.input_dropout(x)\n        timing = self.timing_table[:seq_length]\n        timing = self.timing_dropout(timing)\n        assert timing.shape == (seq_length,), f\"{timing.shape}\"\n        assert timing.unsqueeze(0).unsqueeze(2).shape == (1, seq_length, 1), f\"{timing.unsqueeze(0).unsqueeze(2).shape}\"\n        assert (x + timing.unsqueeze(0).unsqueeze(2)).shape == (batch_size, seq_length, d_model), f\"{(x + timing.unsqueeze(0).unsqueeze(2)).shape}\"\n        assert mask.unsqueeze(-1).expand(-1, -1, d_model).shape == (batch_size, seq_length, d_model), f\"{mask.unsqueeze(-1).expand(-1, -1, d_model)}\"\n        return torch.where(mask.unsqueeze(-1).expand(-1, -1, d_model)==False, x + timing.unsqueeze(0).unsqueeze(2), x)\n\nclass TransformerEmotionModel(EmotionModel):\n    def __init__(self, d_model=512, num_encoder_layers=6, dropout=0.1):\n        super().__init__()\n        self.n_mels = 80\n        self.d_model = d_model\n        self.add_timing = AddPositionalEncoding(d_model)\n        self.num_encoder_layers = num_encoder_layers\n        encoder_ls = []\n        for _ in range(num_encoder_layers):\n            encoder_ls.append(nn.TransformerEncoderLayer(d_model=d_model, nhead=8, batch_first=True, norm_first=False, dropout=dropout, dim_feedforward=d_model))\n        self.encoder_layers = nn.ModuleList(encoder_ls)\n        self.embedding_layer = nn.Embedding(11, d_model) # len(self.label_encoder) = 11\n        self.pre_projection_layer = nn.Linear(self.n_mels, d_model)\n        self.post_projection_layer = nn.Linear(d_model, self.n_mels)\n\n    def transform(self, batch):\n        \n        batch_size, seq_length, _ = batch[\"ai_mel\"].shape\n        assert batch[\"ai_mel\"].shape == (batch_size, seq_length, self.n_mels)\n        \n        batch_input = batch[\"ai_mel\"]\n        assert batch_input.shape == (batch_size, seq_length, self.n_mels)\n        assert not torch.any(torch.isnan(batch_input))\n\n        label = batch[\"labels\"]\n        mask = batch[\"mask\"]\n        \n        assert mask.shape == (batch_size, seq_length)\n        assert not torch.any(torch.isnan(mask))\n        mask = torch.cat((torch.full((batch_size, 1), False).to(device), mask), 1)\n        assert mask.shape == (batch_size, 1 + seq_length)\n        \n        assert label.shape == (batch_size,)\n        label_embedded = self.embedding_layer(label).unsqueeze(1)\n        assert label_embedded.shape == (batch_size, 1, self.d_model)\n        assert not torch.any(torch.isnan(label_embedded))\n        \n        pre_adjoined = self.pre_projection_layer(batch_input)\n        assert pre_adjoined.shape == (batch_size, seq_length, self.d_model)\n        assert not torch.any(torch.isnan(pre_adjoined))\n        \n        adjoined = torch.cat((label_embedded, pre_adjoined), 1)\n        assert adjoined.shape == (batch_size, 1 + seq_length, self.d_model)\n        assert not torch.any(torch.isnan(adjoined))\n        \n        adjoined_with_timing = self.add_timing(adjoined, mask)\n        assert adjoined_with_timing.shape == (batch_size, 1 + seq_length, self.d_model)\n        assert not torch.any(torch.isnan(adjoined_with_timing))\n        \n        after_encoder = adjoined_with_timing\n        \n        for i in range(self.num_encoder_layers):\n            after_encoder = self.encoder_layers[i](after_encoder, src_key_padding_mask=mask)\n            assert after_encoder.shape == (batch_size, 1 + seq_length, self.d_model)\n            assert not torch.any(torch.isnan(after_encoder)) # ERROR\n        \n        post_adjoined = self.post_projection_layer(after_encoder)\n        assert post_adjoined.shape == (batch_size, 1 + seq_length, self.n_mels)\n        assert not torch.any(torch.isnan(post_adjoined))\n        \n        res = post_adjoined[:,1:,:]\n        assert res.shape == (batch_size, seq_length, self.n_mels)\n        assert not torch.any(torch.isnan(res)) # ERROR\n        \n        return res","metadata":{"execution":{"iopub.status.busy":"2024-12-08T19:15:17.964946Z","iopub.execute_input":"2024-12-08T19:15:17.968278Z","iopub.status.idle":"2024-12-08T19:15:18.028687Z","shell.execute_reply.started":"2024-12-08T19:15:17.968219Z","shell.execute_reply":"2024-12-08T19:15:18.027556Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"del transformer_encoder_model","metadata":{"execution":{"iopub.status.busy":"2024-12-08T19:07:51.196384Z","iopub.execute_input":"2024-12-08T19:07:51.197227Z","iopub.status.idle":"2024-12-08T19:07:51.200742Z","shell.execute_reply.started":"2024-12-08T19:07:51.197177Z","shell.execute_reply":"2024-12-08T19:07:51.199885Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transformer_encoder_model = TransformerEmotionModel(d_model=512, num_encoder_layers=6, dropout=0.1)\ntransformer_encoder_model.to(device)\n#transformer_encoder_model.load_state_dict(torch.load(\"/kaggle/input/speaker_2/pytorch/default/1/transformer_encoder_model_speaker_two.pt\"))\n#transformer_encoder_model.load_state_dict(torch.load(\"/kaggle/working/transformer_encoder_model_speaker_two_new.pt\"))","metadata":{"execution":{"iopub.status.busy":"2024-12-08T19:15:20.327621Z","iopub.execute_input":"2024-12-08T19:15:20.327970Z","iopub.status.idle":"2024-12-08T19:15:20.431903Z","shell.execute_reply.started":"2024-12-08T19:15:20.327924Z","shell.execute_reply":"2024-12-08T19:15:20.431011Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train\nTrain loop.","metadata":{}},{"cell_type":"code","source":"# Training\nloss_curve = []\nvalidation_curve = []","metadata":{"execution":{"iopub.status.busy":"2024-12-08T19:15:22.647017Z","iopub.execute_input":"2024-12-08T19:15:22.647387Z","iopub.status.idle":"2024-12-08T19:15:22.651825Z","shell.execute_reply.started":"2024-12-08T19:15:22.647357Z","shell.execute_reply":"2024-12-08T19:15:22.650748Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_processed(model, data, num_epochs, batch_size, model_file,\n          learning_rate=8e-4, loss_curve=[], validation_curve=[], best_metric=None):\n    training_dataset = ProcessedMelSpectrogramDataset(\"train\", data)\n    validation_dataset = ProcessedMelSpectrogramDataset(\"valid\", data)\n    \n    data_loader = torch.utils.data.DataLoader(\n        training_dataset, batch_size=batch_size, shuffle=True, collate_fn=training_dataset.collate\n    )\n    optimizer = torch.optim.Adam(\n        model.parameters(),\n        lr=learning_rate, \n        betas=(0.9, 0.98), \n        eps=1e-9\n    )\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer,\n        learning_rate,\n        epochs=num_epochs,\n        steps_per_epoch=len(data_loader),\n        pct_start=0.02,  # Warm up for 2% of the total training time\n    )\n    \n    for epoch in tqdm.notebook.trange(num_epochs, desc=\"training\", unit=\"epoch\"):\n        logging.info(f\"=== EPOCH {epoch + 1}\")\n        with tqdm.notebook.tqdm(\n            data_loader,\n            desc=\"epoch {}\".format(epoch + 1),\n            unit=\"batch\",\n            total=len(data_loader)) as batch_iterator:\n            model.train()\n            total_loss = 0.0\n            total_num = 0\n            for i, batch in enumerate(batch_iterator, start=1):\n                optimizer.zero_grad()\n                loss = model.compute_loss(batch)\n                total_loss += loss.item()\n                total_num += batch[\"ai_mel\"].size(0)\n                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n                loss.backward()\n                optimizer.step()\n                scheduler.step()\n                batch_iterator.set_postfix(mean_loss=total_loss / total_num)\n            validation_metric = model.get_validation_metric(validation_dataset, batch_size=batch_size)\n            validation_curve.append(validation_metric.item())\n            loss_curve.append(total_loss/total_num)\n            batch_iterator.set_postfix(\n                mean_loss=total_loss / total_num,\n                validation_metric=validation_metric\n            )\n            print(f\"epoch={epoch + 1}; training={total_loss / total_num}; validation={validation_metric}\")\n            logging.info(f\"epoch={epoch + 1}; training={total_loss / total_num}; validation={validation_metric}\")\n            if best_metric is None or validation_metric < best_metric:\n                print(\n                    \"Obtained a new best validation metric of {:.3f}, saving model \"\n                    \"checkpoint to {}...\".format(validation_metric, model_file)\n                )\n                torch.save(model.state_dict(), model_file)\n                best_metric = validation_metric\n        logging.info(f\"=== END OF EPOCH {epoch + 1}\")\n    print(\"Reloading best model checkpoint from {}...\".format(model_file))\n    model.load_state_dict(torch.load(model_file))","metadata":{"execution":{"iopub.status.busy":"2024-12-08T19:15:23.392012Z","iopub.execute_input":"2024-12-08T19:15:23.392504Z","iopub.status.idle":"2024-12-08T19:15:23.407941Z","shell.execute_reply.started":"2024-12-08T19:15:23.392451Z","shell.execute_reply":"2024-12-08T19:15:23.406787Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_processed(\n    transformer_encoder_model, \n    dataset, \n    num_epochs=40, \n    batch_size=64,\n    model_file=\"normalised_transformer_encoder_model_speaker_4.pt\", \n    learning_rate=5e-4, \n    loss_curve=loss_curve, \n    validation_curve=validation_curve,\n    best_metric=None\n)","metadata":{"execution":{"iopub.status.busy":"2024-12-08T19:15:24.868699Z","iopub.execute_input":"2024-12-08T19:15:24.869687Z","iopub.status.idle":"2024-12-08T19:51:37.303325Z","shell.execute_reply.started":"2024-12-08T19:15:24.869627Z","shell.execute_reply":"2024-12-08T19:51:37.302265Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\nplt.plot(np.arange(len(loss_curve)), np.array(loss_curve), label=\"training loss\")\nplt.xlabel('Epoch') \nplt.ylabel('Loss')\nplt.legend()\nplt.title('Training Loss Curve')\nplt.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-12-08T19:52:34.708935Z","iopub.execute_input":"2024-12-08T19:52:34.710106Z","iopub.status.idle":"2024-12-08T19:52:35.037349Z","shell.execute_reply.started":"2024-12-08T19:52:34.710066Z","shell.execute_reply":"2024-12-08T19:52:35.036361Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\nplt.plot(np.arange(len(validation_curve)), validation_curve, label=\"validation loss\")\nplt.xlabel('Epoch') \nplt.ylabel('Loss')\nplt.legend()\nplt.title('Validation Loss Curve')\nplt.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-12-08T19:52:37.235117Z","iopub.execute_input":"2024-12-08T19:52:37.235690Z","iopub.status.idle":"2024-12-08T19:52:37.532406Z","shell.execute_reply.started":"2024-12-08T19:52:37.235651Z","shell.execute_reply":"2024-12-08T19:52:37.531556Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, ax1 = plt.subplots(figsize=(15, 10))\n\nax1.plot(np.arange(len(loss_curve)), np.array(loss_curve), 'b-', label='train')\nax1.set_xlabel('Epoch')\nax1.set_ylabel('Loss (train)', color='b') \nax1.tick_params(axis='y', labelcolor='b')  # Color of y-ticks\n\nax2 = ax1.twinx()\n\nax2.plot(np.arange(len(validation_curve)), validation_curve, 'g-', label='valid')\nax2.set_ylabel('Loss (valid)', color='g')  # Label for the second y-axis\nax2.tick_params(axis='y', labelcolor='g')  # Color of y-ticks\n\nplt.title('Loss Curve')\nplt.legend()\nplt.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-12-08T19:52:39.555393Z","iopub.execute_input":"2024-12-08T19:52:39.556275Z","iopub.status.idle":"2024-12-08T19:52:39.952294Z","shell.execute_reply.started":"2024-12-08T19:52:39.556236Z","shell.execute_reply":"2024-12-08T19:52:39.951429Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(loss_curve)\nprint(validation_curve)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T19:52:44.693750Z","iopub.execute_input":"2024-12-08T19:52:44.694195Z","iopub.status.idle":"2024-12-08T19:52:44.698759Z","shell.execute_reply.started":"2024-12-08T19:52:44.694160Z","shell.execute_reply":"2024-12-08T19:52:44.697885Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Predict\nUse trained model for prediction.","metadata":{}},{"cell_type":"code","source":"def predict_processed(model, data, num_limit=10):\n\n    model.eval()\n\n    test_dataset = ProcessedMelSpectrogramDataset(\"test\", data)\n\n    data_loader = torch.utils.data.DataLoader(\n        test_dataset, batch_size=1, collate_fn=test_dataset.collate\n    )\n    \n    with tqdm.notebook.tqdm(\n        data_loader,\n        total=len(data_loader)) as batch_iterator:\n        model.eval()\n\n        for i, batch in enumerate(batch_iterator, start=1):\n            if i > num_limit: break\n            _, seq_length, n_mels = batch[\"ai_mel\"].shape\n            assert n_mels == 80\n            pred = model.transform(batch)\n            pred = (pred*sig_data_cuda) + mu_data_cuda # de-standardise\n            assert pred.shape == (1, seq_length, n_mels)\n            assert pred.squeeze().shape == (seq_length, n_mels)\n\n            data_mel = (batch[\"data_mel\"]*sig_data_cuda) + mu_data_cuda\n            ai_mel = (batch[\"ai_mel\"]*sig_cuda) + mu_cuda\n            \n            mel_to_audio(pred.squeeze(), f\"test{i}_pred.wav\")\n            mel_to_audio(data_mel.squeeze(), f\"test{i}_actual.wav\")\n            mel_to_audio(ai_mel.squeeze(), f\"test{i}_input.wav\")","metadata":{"execution":{"iopub.status.busy":"2024-12-08T20:00:00.101761Z","iopub.execute_input":"2024-12-08T20:00:00.102709Z","iopub.status.idle":"2024-12-08T20:00:00.109715Z","shell.execute_reply.started":"2024-12-08T20:00:00.102670Z","shell.execute_reply":"2024-12-08T20:00:00.108937Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict_processed(transformer_encoder_model, dataset)","metadata":{"execution":{"iopub.status.busy":"2024-12-08T20:00:00.791617Z","iopub.execute_input":"2024-12-08T20:00:00.791933Z","iopub.status.idle":"2024-12-08T20:00:25.229896Z","shell.execute_reply.started":"2024-12-08T20:00:00.791901Z","shell.execute_reply":"2024-12-08T20:00:25.228985Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_dataset = ProcessedMelSpectrogramDataset(\"test\", dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T20:03:18.167291Z","iopub.execute_input":"2024-12-08T20:03:18.168233Z","iopub.status.idle":"2024-12-08T20:03:18.173394Z","shell.execute_reply.started":"2024-12-08T20:03:18.168183Z","shell.execute_reply":"2024-12-08T20:03:18.172340Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_decoder = {\n    0: 'confused',\n    1: 'default',\n    2: 'emphasis',\n    3: 'enunciated',\n    4: 'essentials',\n    5: 'happy',\n    6: 'laughing',\n    7: 'longform',\n    8: 'sad',\n    9: 'singing',\n    10: 'whisper'\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T20:05:43.447826Z","iopub.execute_input":"2024-12-08T20:05:43.448612Z","iopub.status.idle":"2024-12-08T20:05:43.452814Z","shell.execute_reply.started":"2024-12-08T20:05:43.448572Z","shell.execute_reply":"2024-12-08T20:05:43.451921Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"view_spectrogram(get_spectrogram(\"/kaggle/working/test10_input.wav\"), title=\"Test 10 Input\")","metadata":{"execution":{"iopub.status.busy":"2024-12-08T20:00:49.685028Z","iopub.execute_input":"2024-12-08T20:00:49.685400Z","iopub.status.idle":"2024-12-08T20:00:50.071763Z","shell.execute_reply.started":"2024-12-08T20:00:49.685368Z","shell.execute_reply":"2024-12-08T20:00:50.071002Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mel_to_audio(get_spectrogram(\"/kaggle/working/test10_input.wav\"), display=True)","metadata":{"execution":{"iopub.status.busy":"2024-12-08T20:00:53.023652Z","iopub.execute_input":"2024-12-08T20:00:53.024174Z","iopub.status.idle":"2024-12-08T20:00:54.700839Z","shell.execute_reply.started":"2024-12-08T20:00:53.024122Z","shell.execute_reply":"2024-12-08T20:00:54.699874Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"view_spectrogram(get_spectrogram(\"/kaggle/working/test10_pred.wav\"), title=\"Test 10 Prediction\")","metadata":{"execution":{"iopub.status.busy":"2024-12-08T19:58:11.976529Z","iopub.execute_input":"2024-12-08T19:58:11.976879Z","iopub.status.idle":"2024-12-08T19:58:12.357612Z","shell.execute_reply.started":"2024-12-08T19:58:11.976845Z","shell.execute_reply":"2024-12-08T19:58:12.356721Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mel_to_audio(get_spectrogram(\"/kaggle/working/test10_pred.wav\"), display=True)","metadata":{"execution":{"iopub.status.busy":"2024-12-08T19:58:31.188424Z","iopub.execute_input":"2024-12-08T19:58:31.189144Z","iopub.status.idle":"2024-12-08T19:58:39.004821Z","shell.execute_reply.started":"2024-12-08T19:58:31.189107Z","shell.execute_reply":"2024-12-08T19:58:39.003910Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"view_spectrogram(get_spectrogram(\"/kaggle/working/test10_actual.wav\"), title=\"Test 10 Actual\")","metadata":{"execution":{"iopub.status.busy":"2024-12-08T20:01:04.597233Z","iopub.execute_input":"2024-12-08T20:01:04.597603Z","iopub.status.idle":"2024-12-08T20:01:04.974389Z","shell.execute_reply.started":"2024-12-08T20:01:04.597566Z","shell.execute_reply":"2024-12-08T20:01:04.973640Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mel_to_audio(get_spectrogram(\"/kaggle/working/test10_actual.wav\"), display=True)","metadata":{"execution":{"iopub.status.busy":"2024-12-08T20:01:07.159142Z","iopub.execute_input":"2024-12-08T20:01:07.159503Z","iopub.status.idle":"2024-12-08T20:01:08.826469Z","shell.execute_reply.started":"2024-12-08T20:01:07.159462Z","shell.execute_reply":"2024-12-08T20:01:08.825466Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_decoder[test_dataset[8][\"label\"].item()]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T20:07:12.860533Z","iopub.execute_input":"2024-12-08T20:07:12.861234Z","iopub.status.idle":"2024-12-08T20:07:12.866767Z","shell.execute_reply.started":"2024-12-08T20:07:12.861189Z","shell.execute_reply":"2024-12-08T20:07:12.865835Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"view_spectrogram(get_spectrogram(\"/kaggle/working/test9_input.wav\"), title=\"Test 9 Input\")","metadata":{"execution":{"iopub.status.busy":"2024-12-08T20:01:16.418313Z","iopub.execute_input":"2024-12-08T20:01:16.418630Z","iopub.status.idle":"2024-12-08T20:01:16.788420Z","shell.execute_reply.started":"2024-12-08T20:01:16.418602Z","shell.execute_reply":"2024-12-08T20:01:16.787528Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mel_to_audio(get_spectrogram(\"/kaggle/working/test9_input.wav\"), display=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T20:02:10.426414Z","iopub.execute_input":"2024-12-08T20:02:10.426763Z","iopub.status.idle":"2024-12-08T20:02:11.432087Z","shell.execute_reply.started":"2024-12-08T20:02:10.426730Z","shell.execute_reply":"2024-12-08T20:02:11.431165Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"view_spectrogram(get_spectrogram(\"/kaggle/working/test9_pred.wav\"), title=\"Test 9 Prediction\")","metadata":{"execution":{"iopub.status.busy":"2024-12-08T20:01:18.878876Z","iopub.execute_input":"2024-12-08T20:01:18.879275Z","iopub.status.idle":"2024-12-08T20:01:19.250555Z","shell.execute_reply.started":"2024-12-08T20:01:18.879240Z","shell.execute_reply":"2024-12-08T20:01:19.249702Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mel_to_audio(get_spectrogram(\"/kaggle/working/test9_pred.wav\"), display=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T20:01:35.178026Z","iopub.execute_input":"2024-12-08T20:01:35.178373Z","iopub.status.idle":"2024-12-08T20:01:39.936584Z","shell.execute_reply.started":"2024-12-08T20:01:35.178342Z","shell.execute_reply":"2024-12-08T20:01:39.935649Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"view_spectrogram(get_spectrogram(\"/kaggle/working/test9_actual.wav\"), title=\"Test 9 Actual\")","metadata":{"execution":{"iopub.status.busy":"2024-12-08T20:01:19.917539Z","iopub.execute_input":"2024-12-08T20:01:19.917867Z","iopub.status.idle":"2024-12-08T20:01:20.279732Z","shell.execute_reply.started":"2024-12-08T20:01:19.917835Z","shell.execute_reply":"2024-12-08T20:01:20.278902Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mel_to_audio(get_spectrogram(\"/kaggle/working/test9_actual.wav\"), display=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T20:01:54.606758Z","iopub.execute_input":"2024-12-08T20:01:54.607710Z","iopub.status.idle":"2024-12-08T20:01:55.597508Z","shell.execute_reply.started":"2024-12-08T20:01:54.607652Z","shell.execute_reply":"2024-12-08T20:01:55.596559Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mel_to_audio(get_spectrogram(\"/kaggle/working/test8_actual.wav\"), display=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-12T06:55:13.419567Z","iopub.execute_input":"2024-11-12T06:55:13.420087Z","iopub.status.idle":"2024-11-12T06:55:20.252563Z","shell.execute_reply.started":"2024-11-12T06:55:13.420036Z","shell.execute_reply":"2024-11-12T06:55:20.251458Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mel_to_audio(get_spectrogram(\"/kaggle/working/test8_input.wav\"), display=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-12T06:55:33.276863Z","iopub.execute_input":"2024-11-12T06:55:33.277622Z","iopub.status.idle":"2024-11-12T06:55:35.069869Z","shell.execute_reply.started":"2024-11-12T06:55:33.277579Z","shell.execute_reply":"2024-11-12T06:55:35.068731Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mel_to_audio(get_spectrogram(\"/kaggle/working/test8_pred.wav\"), display=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-12T06:55:50.783722Z","iopub.execute_input":"2024-11-12T06:55:50.78461Z","iopub.status.idle":"2024-11-12T06:55:52.387747Z","shell.execute_reply.started":"2024-11-12T06:55:50.784565Z","shell.execute_reply":"2024-11-12T06:55:52.386767Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mel_to_audio(get_spectrogram(\"/kaggle/working/test7_actual.wav\"), display=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-12T06:56:06.172312Z","iopub.execute_input":"2024-11-12T06:56:06.172989Z","iopub.status.idle":"2024-11-12T06:56:08.172752Z","shell.execute_reply.started":"2024-11-12T06:56:06.172947Z","shell.execute_reply":"2024-11-12T06:56:08.171709Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mel_to_audio(get_spectrogram(\"/kaggle/working/test7_pred.wav\"), display=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-12T06:56:16.793798Z","iopub.execute_input":"2024-11-12T06:56:16.794264Z","iopub.status.idle":"2024-11-12T06:56:17.306297Z","shell.execute_reply.started":"2024-11-12T06:56:16.794216Z","shell.execute_reply":"2024-11-12T06:56:17.305287Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mel_to_audio(get_spectrogram(\"/kaggle/working/test6_actual.wav\"), display=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-12T06:56:27.537086Z","iopub.execute_input":"2024-11-12T06:56:27.537537Z","iopub.status.idle":"2024-11-12T06:56:35.419309Z","shell.execute_reply.started":"2024-11-12T06:56:27.537497Z","shell.execute_reply":"2024-11-12T06:56:35.418233Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mel_to_audio(get_spectrogram(\"/kaggle/working/test6_pred.wav\"), display=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-12T06:56:47.300372Z","iopub.execute_input":"2024-11-12T06:56:47.300806Z","iopub.status.idle":"2024-11-12T06:56:49.574103Z","shell.execute_reply.started":"2024-11-12T06:56:47.300765Z","shell.execute_reply":"2024-11-12T06:56:49.573063Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_decoder[test_dataset[1][\"label\"].item()]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T20:07:38.746353Z","iopub.execute_input":"2024-12-08T20:07:38.746713Z","iopub.status.idle":"2024-12-08T20:07:38.752545Z","shell.execute_reply.started":"2024-12-08T20:07:38.746679Z","shell.execute_reply":"2024-12-08T20:07:38.751697Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"view_spectrogram(get_spectrogram(\"/kaggle/working/test2_input.wav\"), title=\"Test 2 Input\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T20:07:51.985933Z","iopub.execute_input":"2024-12-08T20:07:51.986768Z","iopub.status.idle":"2024-12-08T20:07:52.358664Z","shell.execute_reply.started":"2024-12-08T20:07:51.986732Z","shell.execute_reply":"2024-12-08T20:07:52.357832Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mel_to_audio(get_spectrogram(\"/kaggle/working/test2_input.wav\"), display=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T20:08:58.377027Z","iopub.execute_input":"2024-12-08T20:08:58.377390Z","iopub.status.idle":"2024-12-08T20:08:59.716416Z","shell.execute_reply.started":"2024-12-08T20:08:58.377360Z","shell.execute_reply":"2024-12-08T20:08:59.715483Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"view_spectrogram(get_spectrogram(\"/kaggle/working/test2_pred.wav\"), title=\"Test 2 Prediction\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T20:09:14.791123Z","iopub.execute_input":"2024-12-08T20:09:14.791979Z","iopub.status.idle":"2024-12-08T20:09:15.151271Z","shell.execute_reply.started":"2024-12-08T20:09:14.791908Z","shell.execute_reply":"2024-12-08T20:09:15.150453Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mel_to_audio(get_spectrogram(\"/kaggle/working/test2_pred.wav\"), display=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T20:09:15.696532Z","iopub.execute_input":"2024-12-08T20:09:15.696862Z","iopub.status.idle":"2024-12-08T20:09:16.920730Z","shell.execute_reply.started":"2024-12-08T20:09:15.696830Z","shell.execute_reply":"2024-12-08T20:09:16.919814Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"view_spectrogram(get_spectrogram(\"/kaggle/working/test2_actual.wav\"), title=\"Test 2 Actual\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T20:08:29.368295Z","iopub.execute_input":"2024-12-08T20:08:29.368670Z","iopub.status.idle":"2024-12-08T20:08:29.745379Z","shell.execute_reply.started":"2024-12-08T20:08:29.368636Z","shell.execute_reply":"2024-12-08T20:08:29.744508Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mel_to_audio(get_spectrogram(\"/kaggle/working/test2_actual.wav\"), display=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T20:08:45.722146Z","iopub.execute_input":"2024-12-08T20:08:45.722721Z","iopub.status.idle":"2024-12-08T20:08:51.943106Z","shell.execute_reply.started":"2024-12-08T20:08:45.722688Z","shell.execute_reply":"2024-12-08T20:08:51.942191Z"}},"outputs":[],"execution_count":null}]}